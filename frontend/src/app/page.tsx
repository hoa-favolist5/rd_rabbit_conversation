"use client";

import React, { useCallback, useEffect, useMemo, useRef, useState } from "react";
import { useWebSocket } from "@/hooks/useWebSocket";
import { useAudioPlayer } from "@/hooks/useAudioPlayer";
import { useAWSTranscribe } from "@/hooks/useAWSTranscribe";
import { useWaitingPhrase } from "@/hooks/useWaitingPhrase";
import { RabbitAvatar, ChatHistory, ChatInput, WorkflowTimingDisplay, SearchResultsPanel } from "@/components";
import { createLogger } from "@/utils/logger";
import { unlockAudio, preloadWaitingSounds, setupVisibilityHandler } from "@/utils/audioUnlock";
import { shouldPlayWaitingPhrase } from "@/utils/keywordDetection";
import { detectCommand } from "@/utils/voiceCommands";
import { executeCommand, type CommandContext } from "@/utils/commandExecutor";
import archiveStorage from "@/utils/archiveStorage";
import { toHiragana, preloadConverter } from "@/utils/hiraganaConverter";
import type { ConversationStatus, DomainType, ArchiveItemInfo, SearchResults } from "@/types";
import styles from "./page.module.css";

const log = createLogger("Page");

// WebSocket URL - connect to backend
const WS_URL = process.env.NEXT_PUBLIC_WS_URL || "ws://localhost:3001/ws";

// AWS Transcribe Configuration
// Uses STS temporary credentials from backend for secure authentication
// Japanese (ja-JP) optimized for best speech recognition accuracy
const AWS_TRANSCRIBE_CONFIG = {
  languageCode: "ja-JP",
  sampleRate: 16000,
  useSTS: true, // Fetch temporary credentials from backend
};

// Minimum characters required for final barge-in submission
const BARGE_IN_MIN_CHARS = parseInt(process.env.NEXT_PUBLIC_BARGE_IN_MIN_CHARS || "5", 10);

// Minimum characters for early barge-in detection (using partial transcripts)
const EARLY_BARGE_IN_MIN_CHARS = parseInt(process.env.NEXT_PUBLIC_EARLY_BARGE_IN_MIN_CHARS || "2", 10);

export default function Home() {
  // Unlock AudioContext on first user gesture (required for iOS Safari)
  // and preload waiting sounds into AudioBuffer cache
  useEffect(() => {
    const unlock = () => {
      unlockAudio().then(() => preloadWaitingSounds(20));
      document.removeEventListener("touchstart", unlock);
      document.removeEventListener("click", unlock);
    };
    document.addEventListener("touchstart", unlock, { once: true });
    document.addEventListener("click", unlock, { once: true });
    return () => {
      document.removeEventListener("touchstart", unlock);
      document.removeEventListener("click", unlock);
    };
  }, []);

  // Resume AudioContext when returning from background (iOS PWA)
  useEffect(() => {
    return setupVisibilityHandler();
  }, []);

  // Register service worker for PWA
  useEffect(() => {
    if ("serviceWorker" in navigator) {
      navigator.serviceWorker.register("/sw.js").catch(() => {
        // Service worker registration failed ‚Äî non-critical
      });
    }
  }, []);

  // Pre-load Kuroshiro converter for hiragana normalization
  // This loads the kuromoji dictionary (~17MB) in the background
  useEffect(() => {
    preloadConverter().then((success) => {
      if (success) {
        log.info("‚úÖ Hiragana converter pre-loaded");
      } else {
        log.warn("‚ö†Ô∏è Hiragana converter failed to pre-load");
      }
    });
  }, []);

  const audioPlayer = useAudioPlayer();
  const [voiceDetected, setVoiceDetected] = useState(false);
  
  // Numbered selection state: which card is currently selected/focused
  const [selectedResultIndex, setSelectedResultIndex] = useState<number | null>(null);

  // Track if early barge-in was triggered (reset on final transcript)
  const earlyBargeInTriggeredRef = useRef(false);

  // Queue for audio that arrives while short-waiting is still playing
  const pendingAudioQueueRef = useRef<Array<
    | { type: 'full'; audioData: string; format: string; responseId?: string; isProtected?: boolean }
    | { type: 'chunk'; data: string; format: string; index: number; total: number; isLast: boolean; responseId?: string }
  >>([]);

  // Flush pending audio queue ‚Äî called when short-waiting finishes + delay
  const flushPendingAudio = useCallback(() => {
    const queue = pendingAudioQueueRef.current;
    if (queue.length === 0) return;

    log.debug(`‚úÖ Flushing ${queue.length} pending audio items`);
    pendingAudioQueueRef.current = [];

    for (const item of queue) {
      if (item.type === 'full') {
        audioPlayer.play(item.audioData, item.format, item.responseId, item.isProtected);
      } else {
        audioPlayer.playChunk(item);
      }
    }
  }, [audioPlayer]);

  // Waiting phrase system (short waiting sounds)
  const waitingPhrase = useWaitingPhrase({
    onWaitingComplete: () => {
      log.debug("‚è≥ Short-waiting complete + delay finished, backend audio can play now");
      flushPendingAudio();
    },
    onWaitingStart: () => {
      log.debug("‚è≥ Short-waiting started");
    },
  });

  // Handle full audio from WebSocket (greeting, long_waiting, sequential TTS)
  const handleAudio = useCallback(
    (audioData: string, format: string, responseId?: string, isProtected?: boolean) => {
      log.debug(`üîä Received full audio (responseId: ${responseId?.slice(-8) || "none"}, protected: ${isProtected || false})`);

      // If short-waiting is playing (or in post-delay), queue this audio
      if (waitingPhrase.isWaitingPhrasePlaying()) {
        log.debug("‚è≥ Short-waiting active - queueing backend audio");
        pendingAudioQueueRef.current.push({ type: 'full', audioData, format, responseId, isProtected });
        return;
      }

      audioPlayer.play(audioData, format, responseId, isProtected);
    },
    [audioPlayer, waitingPhrase]
  );

  // Handle audio chunks for parallel TTS streaming
  const handleAudioChunk = useCallback(
    (chunk: { data: string; format: string; index: number; total: number; isLast: boolean; responseId?: string }) => {
      // If short-waiting is playing (or in post-delay), queue ALL chunks
      if (waitingPhrase.isWaitingPhrasePlaying()) {
        log.debug(`‚è≥ Short-waiting active - queueing chunk ${chunk.index}/${chunk.total}`);
        pendingAudioQueueRef.current.push({ type: 'chunk', ...chunk });
        return;
      }

      audioPlayer.playChunk(chunk);
    },
    [audioPlayer, waitingPhrase]
  );

  // Handle item focused from backend (voice number selection "2Áï™")
  const handleItemFocused = useCallback((index: number, itemId: string, domain: DomainType, itemTitle: string) => {
    log.info(`üî¢ Item focused from voice: ${index + 1}Áï™ "${itemTitle}"`);
    setSelectedResultIndex(index);
  }, []);

  const {
    isConnected,
    status: wsStatus,
    emotion,
    statusText,
    messages,
    error,
    workflowTiming,
    userId,
    historyLoaded,
    sendMessage: wsSendMessage,
    requestRandomUser,
    loadHistory,
    requestGreeting,
    saveToArchive,
    sendSelectItem,
  } = useWebSocket({
    url: WS_URL,
    onAudio: handleAudio,
    onAudioChunk: handleAudioChunk,
    onBackendResponse: () => {
      // Backend responded - cancel waiting timer if still waiting
      waitingPhrase.cancelWaitingTimer();
    },
    onItemFocused: handleItemFocused,
  });

  // Save to archive - archiveStorage handles state, ChatHistory uses useArchiveStorage hook
  const handleSaveToArchive = useCallback((
    userId: string,
    domain: DomainType,
    itemId: string,
    itemTitle?: string,
    itemData?: Record<string, unknown>
  ) => {
    // Call WebSocket save - backend will respond with archive_saved
    // useWebSocket will update archiveStorage, which triggers re-render via useArchiveStorage hook
    saveToArchive(userId, domain, itemId, itemTitle, itemData);

    // Optimistically mark as saved in archiveStorage (immediate UI feedback)
    // Include itemTitle and itemData so the item can be created if it doesn't exist
    archiveStorage.updateItem(itemId, domain, { 
      savedAt: new Date(),
      itemTitle,
      itemDomain: domain,
      itemData,
    });
    log.debug(`‚úÖ Optimistic save: ${itemId}`);
  }, [saveToArchive]);

  // Reset selected index when new search results arrive
  const latestSearchResultRef = useRef<SearchResults | undefined>(undefined);
  useEffect(() => {
    const lastMsg = messages[messages.length - 1];
    if (lastMsg?.role === "assistant" && lastMsg.searchResults) {
      if (lastMsg.searchResults !== latestSearchResultRef.current) {
        latestSearchResultRef.current = lastMsg.searchResults;
        setSelectedResultIndex(null);
        log.debug("üîÑ New search results arrived, reset selection");
      }
    }
  }, [messages]);

  // Handle card selection from touch (tap on card)
  const handleCardSelect = useCallback((index: number, itemId: string, action: "focus" | "detail" | "save") => {
    log.info(`üëÜ Card selected: ${index + 1}Áï™, action=${action}`);
    setSelectedResultIndex(index);
    
    // Send to backend so LLM knows the selection
    sendSelectItem(index, itemId, action);
    
    // If action is "save", also trigger archive save
    if (action === "save" && userId) {
      const lastMsg = messages[messages.length - 1];
      if (lastMsg?.searchResults) {
        const { searchResults } = lastMsg;
        if (searchResults.type === "movie" && searchResults.movies?.[index]) {
          const movie = searchResults.movies[index];
          const movieItemId = movie.id?.toString() || itemId;
          handleSaveToArchive(userId, "movie", movieItemId, movie.title_ja, {
            title_en: movie.title_en,
            description: movie.description,
            release_year: movie.release_year,
            rating: movie.rating,
            director: movie.director,
            actors: movie.actors,
          });
        } else if (searchResults.type === "gourmet" && searchResults.restaurants?.[index]) {
          const restaurant = searchResults.restaurants[index];
          const restaurantItemId = restaurant.id?.toString() || itemId;
          handleSaveToArchive(userId, "gourmet", restaurantItemId, restaurant.name, {
            code: restaurant.code,
            address: restaurant.address,
            catch_copy: restaurant.catch_copy,
            urls_pc: restaurant.urls_pc,
            open_hours: restaurant.open_hours,
          });
        }
      }
    }
  }, [sendSelectItem, userId, messages, handleSaveToArchive]);

  // Push archivable items to storage when they arrive
  useEffect(() => {
    const lastMessage = messages[messages.length - 1];
    if (lastMessage?.role === "assistant") {
      try {
        // Push single archiveItem (for backward compatibility)
        if (lastMessage.archiveItem) {
          archiveStorage.push(lastMessage.archiveItem);
          log.debug(`üì• Pushed single item to archive storage: ${lastMessage.archiveItem.itemTitle}`);
        }
        
        // Push all items from searchResults (batch operation for multiple results)
        if (lastMessage.searchResults) {
          const { searchResults } = lastMessage;
          const itemsToPush: ArchiveItemInfo[] = [];
          
          if (searchResults.type === "movie" && searchResults.movies) {
            searchResults.movies.forEach((movie) => {
              itemsToPush.push({
                itemId: movie.id?.toString() || `movie-${Date.now()}-${Math.random()}`,
                itemTitle: movie.title_ja,
                itemDomain: "movie",
                itemData: {
                  title_en: movie.title_en,
                  description: movie.description,
                  release_year: movie.release_year,
                  rating: movie.rating,
                  director: movie.director,
                  actors: movie.actors,
                },
              });
            });
          }
          
          if (searchResults.type === "gourmet" && searchResults.restaurants) {
            searchResults.restaurants.forEach((restaurant) => {
              itemsToPush.push({
                itemId: restaurant.id?.toString() || `gourmet-${Date.now()}-${Math.random()}`,
                itemTitle: restaurant.name,
                itemDomain: "gourmet",
                itemData: {
                  code: restaurant.code,
                  address: restaurant.address,
                  catch_copy: restaurant.catch_copy,
                  urls_pc: restaurant.urls_pc,
                  open_hours: restaurant.open_hours,
                  close_days: restaurant.close_days,
                  access: restaurant.access,
                },
              });
            });
          }
          
          // Batch push all items at once (more efficient)
          if (itemsToPush.length > 0) {
            archiveStorage.pushMany(itemsToPush);
            log.debug(`üì• Batch pushed ${itemsToPush.length} ${searchResults.type} items to archive storage`);
          }
        }
      } catch (error) {
        log.error("Failed to push to archive storage:", error);
      }
    }
  }, [messages]);

  // Auto-fetch random user when WebSocket connects, then load history
  useEffect(() => {
    if (isConnected && requestRandomUser) {
      log.info("üîê WebSocket connected - requesting random user...");
      setTimeout(() => {
        requestRandomUser();
        log.info('üì® Random user request sent');
      }, 100);
    }
  }, [isConnected, requestRandomUser]);

  // Load history after user is set, then request greeting
  useEffect(() => {
    if (userId && !historyLoaded) {
      log.info(`üìú User set (${userId}) - loading history...`);
      setTimeout(() => {
        loadHistory(userId, 5); // Load 5 most recent items
        log.info('üì® History load request sent');
      }, 200);
    }
  }, [userId, historyLoaded, loadHistory]);

  // Request greeting after history is loaded
  useEffect(() => {
    if (historyLoaded) {
      log.info("‚úÖ History loaded - requesting greeting...");
      setTimeout(() => {
        requestGreeting();
        log.info('üëã Greeting request sent');
      }, 300);
    }
  }, [historyLoaded, requestGreeting]);

  // Send message - cancel all audio and send to backend
  // Only convert to hiragana when movie/gourmet keywords detected (for better search matching)
  // Normal conversation keeps original text for better Claude response quality
  const sendMessage = useCallback(async (text: string) => {
    log.debug(`üì§ Sending message: "${text}"`);

    // CRITICAL: Cancel all audio - stops current playback and rejects old audio
    audioPlayer.cancelAllAudio();

    // Clear any pending audio waiting for short-waiting to finish
    pendingAudioQueueRef.current = [];

    // Stop any waiting phrase
    waitingPhrase.stopWaitingPhrase();

    // üéØ CHECK FOR COMMANDS FIRST (works for both text and voice input)
    const command = detectCommand(text);
    
    if (command) {
      log.info(`‚å®Ô∏è Text command detected: ${command.type} (keyword: "${command.keyword}")`);
      
      // Execute command locally with full context (search results, selection, etc.)
      const commandContext: CommandContext = {
        userId,
        saveToArchive: handleSaveToArchive,
        originalText: text,
        messages,
        selectedIndex: selectedResultIndex,
      };
      
      const result = executeCommand(command.type, commandContext);
      
      if (result.success) {
        log.info(`‚úÖ Command executed: ${result.message}`);
      } else {
        log.warn(`‚ùå Command failed: ${result.message}`);
      }
      
      // Check if we should still send to backend
      if (!result.shouldSendToBackend) {
        log.debug("‚èπÔ∏è Command handled locally, not sending to backend");
        return; // Don't send to backend
      }
    }

    // No command or command wants to send to backend
    // Check if message contains movie/gourmet keywords
    const hasDbKeywords = shouldPlayWaitingPhrase(text);
    log.debug(`üîç Keyword detection: ${hasDbKeywords ? "movie/gourmet detected" : "traditional conversation"}`);

    // Start waiting timer only if keywords detected (will play short waiting sound if backend takes > 1s)
    waitingPhrase.startWaitingTimer(hasDbKeywords);

    // Only convert to hiragana if movie/gourmet keywords detected
    // This helps backend match movie/restaurant names regardless of how STT outputs them
    // Normal conversation keeps original text for better Claude response quality
    if (hasDbKeywords) {
      try {
        const hiraganaText = await toHiragana(text);
        log.debug(`üìù Hiragana conversion: "${text}" ‚Üí "${hiraganaText}"`);
        wsSendMessage(hiraganaText);
      } catch (error) {
        log.warn("‚ö†Ô∏è Hiragana conversion failed, sending original text:", error);
        wsSendMessage(text);
      }
    } else {
      // Normal conversation - send original text
      wsSendMessage(text);
    }
  }, [wsSendMessage, audioPlayer, waitingPhrase, userId, handleSaveToArchive, messages, selectedResultIndex]);

  // AWS Transcribe for voice input
  const transcribe = useAWSTranscribe({
    config: AWS_TRANSCRIBE_CONFIG,
    // Auto-refresh session every 5 minutes to maintain quality
    enableAutoRefresh: true,
    sessionRefreshInterval: 5 * 60 * 1000, // 5 minutes
    inactivityTimeout: 10000, // 10 seconds
    stopOnTabHidden: true,
    onTranscript: useCallback((text: string, isFinal: boolean) => {
      log.debug(`üìù Transcript ${isFinal ? "(final)" : "(interim)"}:`, text);

      const trimmedText = text.trim();

      // EARLY BARGE-IN: Stop audio when we detect speech
      if (!isFinal && trimmedText.length >= EARLY_BARGE_IN_MIN_CHARS) {
        if ((audioPlayer.isPlaying || wsStatus === "speaking") && !earlyBargeInTriggeredRef.current) {
          log.debug(`üü° EARLY BARGE-IN: Stopping audio (${trimmedText.length} chars detected)`);
          audioPlayer.cancelAllAudio();
          earlyBargeInTriggeredRef.current = true;
        }
      }

      // FINAL: Submit transcript
      if (isFinal && trimmedText) {
        earlyBargeInTriggeredRef.current = false;

        if (trimmedText.length < BARGE_IN_MIN_CHARS) {
          log.debug(`‚è≠Ô∏è Transcript too short (${trimmedText.length} chars), ignoring`);
          return;
        }

        // Regular barge-in if early wasn't triggered
        if (audioPlayer.isPlaying || wsStatus === "speaking") {
          log.debug("üîá REGULAR BARGE-IN: Stopping audio");
          audioPlayer.cancelAllAudio();
        }

        // Send to sendMessage - it will handle command detection and hiragana conversion
        log.debug(`‚úÖ Submitting: "${trimmedText}"`);
        sendMessage(trimmedText).catch((err) => {
          log.error("Failed to send message:", err);
        });
      }
    }, [audioPlayer, wsStatus, sendMessage]),
    onError: useCallback((err: Error) => {
      log.error("AWS Transcribe error:", err);
    }, []),
  });

  // VAD for visual feedback
  const checkVoiceActivity = useCallback(() => {
    setVoiceDetected(transcribe.interimTranscript.length > 0);
  }, [transcribe.interimTranscript]);

  React.useEffect(() => {
    checkVoiceActivity();
  }, [checkVoiceActivity]);

  // Compute focused item info for the focus strip in chat section
  const focusedItem = useMemo(() => {
    if (selectedResultIndex === null) return null;
    const lastMsg = [...messages].reverse().find(
      m => m.role === "assistant" && m.searchResults && m.searchResults.total > 0
    );
    if (!lastMsg?.searchResults) return null;
    const { searchResults } = lastMsg;
    if (searchResults.type === "movie" && searchResults.movies) {
      const movie = searchResults.movies[selectedResultIndex];
      if (!movie) return null;
      return { name: movie.title_ja, index: selectedResultIndex, itemId: movie.id?.toString() || `movie-${Date.now()}` };
    }
    if (searchResults.type === "gourmet" && searchResults.restaurants) {
      const restaurant = searchResults.restaurants[selectedResultIndex];
      if (!restaurant) return null;
      return { name: restaurant.name, index: selectedResultIndex, itemId: restaurant.id?.toString() || `gourmet-${Date.now()}` };
    }
    return null;
  }, [selectedResultIndex, messages]);

  // Derive status
  const status: ConversationStatus = useMemo(() => {
    if (audioPlayer.isPlaying) return "speaking";
    return wsStatus;
  }, [audioPlayer.isPlaying, wsStatus]);

  const displayStatusText = useMemo(() => {
    if (audioPlayer.isPlaying) return "Ë©±„Åó„Å¶„ÅÑ„Åæ„Åô...";
    return statusText;
  }, [audioPlayer.isPlaying, statusText]);

  return (
    <div className={styles.container}>
      <header className={styles.header}>
        <h1 className={styles.title}>Lovvit Archive</h1>
        <p className={styles.subtitle}>Êó•Êú¨Ë™û‰ºöË©±AI„Ç¢„Ç∑„Çπ„Çø„É≥„Éà</p>
      </header>

      <main className={styles.main}>
        {/* Left: Avatar & Status */}
        <aside className={styles.avatarSection}>
          <RabbitAvatar
            emotion={emotion}
            status={status}
            statusText={displayStatusText}
            isConnected={isConnected}
          />

          {audioPlayer.isPlaying && (
            <div className={styles.audioIndicator}>
              <span className={styles.audioWave}>üîä</span>
              <span>Èü≥Â£∞ÂÜçÁîü‰∏≠...</span>
            </div>
          )}

          {error && (
            <div className={styles.error}>
              <span>‚ö†Ô∏è</span>
              <span>{error}</span>
            </div>
          )}

          <WorkflowTimingDisplay timing={workflowTiming} />
        </aside>

        {/* Center: Chat (text only) */}
        <section className={styles.chatSection}>
          <ChatHistory
            messages={messages}
            userId={userId}
            onSaveToArchive={handleSaveToArchive}
            textOnly={true}
          />
          {/* Focus strip - shows when an item is selected via voice/touch */}
          {focusedItem && (
            <div className={styles.focusStrip}>
              <span className={styles.focusNumber}>{focusedItem.index + 1}</span>
              <span className={styles.focusTitle}>{focusedItem.name}</span>
              <div className={styles.focusActions}>
                <button
                  className={`${styles.focusBtn} ${styles.focusBtnSave}`}
                  onClick={() => handleCardSelect(focusedItem.index, focusedItem.itemId, "save")}
                >
                  ‰øùÂ≠ò
                </button>
                <button
                  className={`${styles.focusBtn} ${styles.focusBtnDetail}`}
                  onClick={() => handleCardSelect(focusedItem.index, focusedItem.itemId, "detail")}
                >
                  Ë©≥Á¥∞
                </button>
              </div>
            </div>
          )}
          <ChatInput
            onSendMessage={sendMessage}
            status={status}
            disabled={!isConnected}
            isListening={transcribe.isListening}
            onStartListening={transcribe.startListening}
            onStopListening={transcribe.stopListening}
            interimTranscript={transcribe.interimTranscript}
            voiceDetected={voiceDetected}
            transcribeError={transcribe.error}
          />
        </section>

        {/* Right: Search Results Panel (components only) */}
        <aside className={styles.resultsSection}>
          <SearchResultsPanel
            messages={messages}
            userId={userId}
            onSaveToArchive={handleSaveToArchive}
            selectedIndex={selectedResultIndex}
            onCardSelect={handleCardSelect}
          />
        </aside>
      </main>
    </div>
  );
}
