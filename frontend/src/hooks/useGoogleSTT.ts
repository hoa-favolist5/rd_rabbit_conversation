/**
 * Google Cloud STT hook - Streams audio via backend WebSocket
 * 
 * Handles real-time speech-to-text using Google Cloud Speech-to-Text.
 * Audio is captured in the browser, sent to the backend via WebSocket,
 * and the backend streams it to Google Cloud STT and returns transcripts.
 * 
 * Includes "interim stability" detection: if an interim transcript stays
 * unchanged for a configurable period, it is promoted to a final transcript.
 * This replaces AWS Transcribe's built-in PartialResultsStability feature.
 * 
 * Provides the same interface as useAWSTranscribe for easy migration.
 */

import { useState, useRef, useCallback, useEffect } from "react";
import { AudioCaptureManager } from "@/utils/audioUtils";
import { createLogger } from "@/utils/logger";

const log = createLogger("GoogleSTT");

/**
 * Global STT Instance Manager
 * Ensures only one STT session is active at a time
 */
class STTInstanceManager {
  private static activeInstance: {
    stopListening: () => void;
    id: string;
  } | null = null;

  static register(stopListening: () => void, id: string): void {
    if (this.activeInstance && this.activeInstance.id !== id) {
      log.debug(`ğŸ”„ Stopping previous STT instance (${this.activeInstance.id})`);
      this.activeInstance.stopListening();
    }
    this.activeInstance = { stopListening, id };
    log.debug(`âœ… Registered STT instance: ${id}`);
  }

  static unregister(id: string): void {
    if (this.activeInstance?.id === id) {
      log.debug(`ğŸ—‘ï¸ Unregistered STT instance: ${id}`);
      this.activeInstance = null;
    }
  }
}

export interface GoogleSTTConfig {
  languageCode: string;   // e.g. "ja-JP"
  sampleRate: number;     // e.g. 16000
  model?: string;         // e.g. "default", "latest_long"
}

export interface UseGoogleSTTOptions {
  config: GoogleSTTConfig;
  /** Reference to the app WebSocket */
  wsRef: React.RefObject<WebSocket | null>;
  /** Whether the WebSocket is connected */
  wsConnected: boolean;
  onTranscript?: (text: string, isFinal: boolean) => void;
  onError?: (error: Error) => void;
  onStart?: () => void;
  onStop?: () => void;
  // Auto-stop configuration
  inactivityTimeout?: number;     // ms of silence before auto-stop (0 = disabled, default: 0)
  stopOnTabHidden?: boolean;      // Stop when tab hidden (default: true)
  // Interim stability: promote unchanged interim to final after this delay (ms)
  interimStabilityMs?: number;    // default: 1500 (1.5 seconds)
}

export interface UseGoogleSTTReturn {
  isListening: boolean;
  transcript: string;
  interimTranscript: string;
  startListening: () => Promise<void>;
  stopListening: () => void;
  error: Error | null;
}

/**
 * Helper: Convert Uint8Array to base64 string
 */
function uint8ArrayToBase64(data: Uint8Array): string {
  let binary = "";
  for (let i = 0; i < data.length; i++) {
    binary += String.fromCharCode(data[i]);
  }
  return btoa(binary);
}

export function useGoogleSTT({
  config,
  wsRef,
  wsConnected,
  onTranscript,
  onError,
  onStart,
  onStop,
  inactivityTimeout = 0,        // Disabled by default â€” user clicks mic to stop
  stopOnTabHidden = true,
  interimStabilityMs = 1500,    // 1.5 seconds â€” promote stable interim to final
}: UseGoogleSTTOptions): UseGoogleSTTReturn {
  const [isListening, setIsListening] = useState(false);
  const [transcript, setTranscript] = useState("");
  const [interimTranscript, setInterimTranscript] = useState("");
  const [error, setError] = useState<Error | null>(null);

  const audioCapture = useRef<AudioCaptureManager | null>(null);
  const inactivityTimer = useRef<NodeJS.Timeout | null>(null);
  const instanceId = useRef<string>(`google-stt-${Date.now()}-${Math.random().toString(36).substr(2, 9)}`);
  const isListeningRef = useRef(false); // Ref to track listening state in callbacks
  const onTranscriptRef = useRef(onTranscript);
  const onErrorRef = useRef(onError);
  const onStartRef = useRef(onStart);
  const onStopRef = useRef(onStop);

  // Interim stability detection refs
  const stabilityTimer = useRef<NodeJS.Timeout | null>(null);
  const lastInterimText = useRef<string>("");

  // Keep refs updated
  useEffect(() => {
    onTranscriptRef.current = onTranscript;
    onErrorRef.current = onError;
    onStartRef.current = onStart;
    onStopRef.current = onStop;
  }, [onTranscript, onError, onStart, onStop]);

  // â”€â”€â”€ Clear stability timer â”€â”€â”€
  const clearStabilityTimer = useCallback(() => {
    if (stabilityTimer.current) {
      clearTimeout(stabilityTimer.current);
      stabilityTimer.current = null;
    }
  }, []);

  // â”€â”€â”€ Promote current interim transcript to final â”€â”€â”€
  const promoteInterimToFinal = useCallback((text: string) => {
    if (!text || !isListeningRef.current) return;

    log.debug(`â±ï¸ Interim stable for ${interimStabilityMs}ms â†’ promoting to final: "${text}"`);

    // Clear stability state
    clearStabilityTimer();
    lastInterimText.current = "";

    // Emit as final transcript
    setTranscript(text);
    setInterimTranscript("");
    onTranscriptRef.current?.(text, true);
  }, [interimStabilityMs, clearStabilityTimer]);

  // â”€â”€â”€ WebSocket message listener for STT responses â”€â”€â”€
  useEffect(() => {
    const ws = wsRef.current;
    if (!ws) return;

    const handleMessage = (event: MessageEvent) => {
      try {
        const message = JSON.parse(event.data);

        switch (message.type) {
          case "stt_transcript": {
            const text = message.text || "";
            const isFinal = message.isFinal || false;

            if (text) {
              log.debug(`ğŸ“ Transcript ${isFinal ? "(final)" : "(interim)"}:`, text);

              // Reset inactivity timer on any speech
              resetInactivityTimer();

              if (isFinal) {
                // Google sent a real final â€” use it directly
                clearStabilityTimer();
                lastInterimText.current = "";

                setTranscript(text);
                setInterimTranscript("");
                onTranscriptRef.current?.(text, true);
              } else {
                // Interim transcript â€” start/reset stability timer
                setInterimTranscript(text);
                onTranscriptRef.current?.(text, false);

                // If text changed, reset the stability timer
                if (text !== lastInterimText.current) {
                  lastInterimText.current = text;
                  clearStabilityTimer();
                  stabilityTimer.current = setTimeout(() => {
                    promoteInterimToFinal(text);
                  }, interimStabilityMs);
                }
                // If text is the same, the existing timer continues counting
              }
            }
            break;
          }

          case "stt_started":
            log.debug("âœ… Backend confirmed STT started");
            break;

          case "stt_stopped":
            log.debug("ğŸ›‘ Backend confirmed STT stopped");
            break;

          case "stt_error": {
            const errMsg = message.error || "Unknown STT error";
            log.error("âŒ Backend STT error:", errMsg);
            const err = new Error(errMsg);
            setError(err);
            onErrorRef.current?.(err);
            break;
          }
        }
      } catch {
        // Ignore non-JSON messages or parse errors
      }
    };

    ws.addEventListener("message", handleMessage);
    return () => {
      ws.removeEventListener("message", handleMessage);
    };
  }, [wsRef.current, interimStabilityMs, clearStabilityTimer, promoteInterimToFinal]); // Re-attach when WebSocket changes

  // â”€â”€â”€ Inactivity timer â”€â”€â”€
  const resetInactivityTimer = useCallback(() => {
    if (inactivityTimer.current) {
      clearTimeout(inactivityTimer.current);
    }

    if (inactivityTimeout > 0 && isListeningRef.current) {
      inactivityTimer.current = setTimeout(() => {
        // Before stopping, check if there's a pending interim transcript
        if (lastInterimText.current) {
          log.debug("â±ï¸ Inactivity timeout â€” promoting pending interim before stop");
          promoteInterimToFinal(lastInterimText.current);
        }
        log.debug("â±ï¸ Inactivity timeout - stopping STT");
        stopListeningInternal();
      }, inactivityTimeout);
    }
  }, [inactivityTimeout, promoteInterimToFinal]);

  // â”€â”€â”€ Stop listening (internal) â”€â”€â”€
  const stopListeningInternal = useCallback(() => {
    if (!isListeningRef.current) return;

    log.debug("ğŸ›‘ Stopping Google STT...");
    isListeningRef.current = false;

    // Unregister from global manager
    STTInstanceManager.unregister(instanceId.current);

    // Clear all timers
    if (inactivityTimer.current) {
      clearTimeout(inactivityTimer.current);
      inactivityTimer.current = null;
    }
    clearStabilityTimer();
    lastInterimText.current = "";

    // Stop audio capture
    if (audioCapture.current) {
      audioCapture.current.stop();
      audioCapture.current = null;
    }

    // Tell backend to stop STT
    try {
      const ws = wsRef.current;
      if (ws && ws.readyState === WebSocket.OPEN) {
        ws.send(JSON.stringify({ type: "stt_stop" }));
      }
    } catch (err) {
      log.error("Error sending stt_stop:", err);
    }

    setIsListening(false);
    onStopRef.current?.();
  }, [wsRef, clearStabilityTimer]);

  // Public stopListening
  const stopListening = useCallback(() => {
    stopListeningInternal();
  }, [stopListeningInternal]);

  // â”€â”€â”€ Tab visibility handler â”€â”€â”€
  useEffect(() => {
    if (!stopOnTabHidden) return;

    const handleVisibilityChange = () => {
      if (document.hidden && isListeningRef.current) {
        log.debug("ğŸ‘ï¸ Tab hidden - stopping STT");
        stopListeningInternal();
      }
    };

    document.addEventListener("visibilitychange", handleVisibilityChange);
    return () => {
      document.removeEventListener("visibilitychange", handleVisibilityChange);
    };
  }, [stopOnTabHidden, stopListeningInternal]);

  // â”€â”€â”€ Cleanup on unmount â”€â”€â”€
  useEffect(() => {
    return () => {
      if (inactivityTimer.current) clearTimeout(inactivityTimer.current);
      clearStabilityTimer();
      stopListeningInternal();
    };
  }, [stopListeningInternal, clearStabilityTimer]);

  // â”€â”€â”€ Start listening â”€â”€â”€
  const startListening = useCallback(async () => {
    if (isListeningRef.current) return;

    const ws = wsRef.current;
    if (!ws || ws.readyState !== WebSocket.OPEN) {
      const err = new Error("WebSocket not connected. Cannot start speech recognition.");
      setError(err);
      onErrorRef.current?.(err);
      return;
    }

    // Register with global manager (stops other instances)
    STTInstanceManager.register(stopListeningInternal, instanceId.current);

    try {
      log.debug("ğŸ™ï¸ Starting Google STT...");
      setError(null);
      setTranscript("");
      setInterimTranscript("");
      lastInterimText.current = "";
      clearStabilityTimer();

      // Tell backend to start STT stream
      ws.send(JSON.stringify({
        type: "stt_start",
        languageCode: config.languageCode || "ja-JP",
        sampleRate: config.sampleRate || 16000,
        model: config.model,
      }));

      // Create audio capture manager
      audioCapture.current = new AudioCaptureManager({
        sampleRate: config.sampleRate,
        channelCount: 1,
      });

      // Start audio capture - send chunks to backend via WebSocket
      await audioCapture.current.start((audioData: Uint8Array) => {
        try {
          if (wsRef.current && wsRef.current.readyState === WebSocket.OPEN && isListeningRef.current) {
            // Send audio data as base64 JSON message
            const base64Data = uint8ArrayToBase64(audioData);
            wsRef.current.send(JSON.stringify({
              type: "stt_audio",
              data: base64Data,
            }));
          }
        } catch (err) {
          log.error("Error sending audio data:", err);
        }
      });

      isListeningRef.current = true;
      setIsListening(true);
      onStartRef.current?.();

      // Start inactivity timer (if enabled)
      resetInactivityTimer();

      // NOTE: No frontend auto-refresh needed. The backend's GoogleSTTSession
      // automatically handles the Google 5-minute stream limit by restarting
      // the stream transparently. Audio capture stays uninterrupted.

      log.debug("âœ… Google STT started successfully", {
        languageCode: config.languageCode,
        sampleRate: config.sampleRate,
      });
    } catch (err) {
      const error = err instanceof Error ? err : new Error(String(err));
      log.error("âŒ Failed to start Google STT:", error);

      // Enhanced error messages
      let userMessage = error.message;
      if (error.message.includes("Permission denied") || error.message.includes("not-allowed")) {
        userMessage = "ãƒã‚¤ã‚¯ã®ä½¿ç”¨è¨±å¯ãŒå¿…è¦ã§ã™ã€‚ãƒ–ãƒ©ã‚¦ã‚¶ã®è¨­å®šã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚";
      } else if (error.message.includes("NotFoundError")) {
        userMessage = "ãƒã‚¤ã‚¯ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒã‚¤ã‚¯ãŒæ¥ç¶šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚";
      } else if (error.message.includes("WebSocket")) {
        userMessage = "ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚ã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚";
      }

      const enhancedError = new Error(userMessage);
      enhancedError.stack = error.stack;

      setError(enhancedError);
      onErrorRef.current?.(enhancedError);

      // Cleanup on error
      stopListeningInternal();
    }
  }, [config, wsRef, stopListeningInternal, resetInactivityTimer, clearStabilityTimer]);

  return {
    isListening,
    transcript,
    interimTranscript,
    startListening,
    stopListening,
    error,
  };
}
